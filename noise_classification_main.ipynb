{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsNck7fXX_bG",
    "outputId": "3841a2c8-fe5e-42f1-d637-be32462b95b3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob \n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels import robust\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import IPython.display as ipd \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tK8Z2Me6CuMk"
   },
   "outputs": [],
   "source": [
    "#initializing all the file path to a variable\n",
    "AUDIO_PATH = r'C:\\Users\\harsh\\Desktop\\esc50 and YBSS-200'\n",
    "CSV_PATH = r'C:\\Users\\harsh\\Desktop\\noise_classifiaction\\excel sheets\\esc50andYBSS200.csv'\n",
    "CSV_PATH1 = r'C:\\Users\\harsh\\Desktop\\noise_classifiaction\\excel sheets\\first5keywords.csv'\n",
    "CSV_PATH2 = r'C:\\Users\\harsh\\Desktop\\noise_classifiaction\\excel sheets\\first10keywords.csv'\n",
    "CSV_PATH3 = r'C:\\Users\\harsh\\Desktop\\noise_classifiaction\\excel sheets\\first15keywords.csv'\n",
    "CSV_PATH4 = r'C:\\Users\\harsh\\Desktop\\noise_classifiaction\\excel sheets\\YBSS_dataset.csv'\n",
    "CSV_PATH5 = r'C:\\Users\\harsh\\Desktop\\noise_classifiaction\\excel sheets\\esc50new.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctuhOPQ4CJmk"
   },
   "source": [
    "## Part 1: Primary data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "0vd3XnyAW9j9",
    "outputId": "4b81e6df-c23b-4237-891f-ac5e9288b475"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH3)\n",
    "print(\"shape of df: \", df.shape)\n",
    "df.head()\n",
    "\n",
    "#checking the content of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwTPAZUEfzol",
    "outputId": "386bcb90-afb0-41d4-b008-b3294e3e7f2a"
   },
   "outputs": [],
   "source": [
    "df=df.drop(['fold','esc10','src_file','take'], axis=1)\n",
    "print(\"shape of df: \", df.shape)\n",
    "print(df)\n",
    "#filtering the table and removing the unwanted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2VfxtizW9Vu",
    "outputId": "98558e91-eb27-41a6-94d3-543ab39692f7"
   },
   "outputs": [],
   "source": [
    "#check NAS\n",
    "df.isna().sum()\n",
    "#checking for any file empty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXGYtMZ0cgl3",
    "outputId": "166c20ec-dfb7-44ac-ddaf-674f5e55a983"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(df['category'].unique())\n",
    "len(df['category'].unique())\n",
    "\n",
    "#printing all the unique catagories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxpwL1hhf7Qt",
    "outputId": "b234f718-2794-4ca4-85cf-900f0a0656fe"
   },
   "outputs": [],
   "source": [
    "df['target'].value_counts()\n",
    "\n",
    "#checking if all classes have 40 audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v66smL1VdODB",
    "outputId": "d1325248-d05c-4e39-f989-8da0881a1480"
   },
   "outputs": [],
   "source": [
    "len(df) == len(df['filename'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yATrXmk0dqWs",
    "outputId": "5f77a246-d86a-4c42-a039-eae30c85b8bb"
   },
   "outputs": [],
   "source": [
    "classes = df['category'].unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVDUPlGXhkJK"
   },
   "source": [
    "## Part 2: Analysis of audio tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "gY3z5qgwZsiT",
    "outputId": "41ecc34d-f17c-4d92-f58c-05c426ddd470"
   },
   "outputs": [],
   "source": [
    "## an instance of each class\n",
    "unique_class_df = df.drop_duplicates(subset=['target'])\n",
    "unique_class_df.head()\n",
    "classes = df['category'].unique()\n",
    "class_dict = {i:x for x,i in enumerate(classes)}\n",
    "df['target'] = df['category'].map(class_dict)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFMFZXgzKhnd",
    "outputId": "03c07bc6-4b81-4a7b-b5e6-d4360390f18f"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for data in tqdm(df.iterrows(),  desc='Progress'):\n",
    "    sig , sr = librosa.load(AUDIO_PATH + \"\\\\\" + data[1][0],sr = 44100)\n",
    "    #taking 3 windows from 0-2 , 2-4 , 3-5 seconds\n",
    "    sig_ = sig[0 : 88200]\n",
    "    if robust.mad(sig_, axis=0) > 1e-4:\n",
    "        mfcc_ = librosa.feature.mfcc(sig_ , sr=sr,hop_length = 512, n_mfcc=40)\n",
    "        X.append(mfcc_)\n",
    "        y.append(data[1][1])\n",
    "    sig_ = sig[88200 : 176400]\n",
    "    if robust.mad(sig_, axis=0) > 1e-4:\n",
    "        mfcc_ = librosa.feature.mfcc(sig_ , sr=sr,hop_length = 512, n_mfcc=40)\n",
    "        X.append(mfcc_)\n",
    "        y.append(data[1][1])\n",
    "    sig_ = sig[132300 : 220500]\n",
    "    if robust.mad(sig_, axis=0) > 1e-4:\n",
    "        mfcc_ = librosa.feature.mfcc(sig_ , sr=sr,hop_length = 512, n_mfcc=40)\n",
    "        X.append(mfcc_)\n",
    "        y.append(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.title(\"Single Bark Wave Plot\")\n",
    "librosa.display.waveshow(sig_,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEgo82QjTYdX"
   },
   "outputs": [],
   "source": [
    "X = np.array(X) \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4Pl6F_hT8mF",
    "outputId": "00fb8fe6-24ff-4c0f-ba74-2ede75bf67ef"
   },
   "outputs": [],
   "source": [
    "print(\"X Shape is: \", X.shape)\n",
    "print(\"y Shape is: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXNMizg6KhkE"
   },
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y , num_classes=15)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dYS7to3KhiJ"
   },
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y ,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzxaBlY3KhgK"
   },
   "outputs": [],
   "source": [
    "INPUTSHAPE = (40,173,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUmQmIddThwW",
    "outputId": "82a196a2-c374-4600-cbb9-3520800db9ba"
   },
   "outputs": [],
   "source": [
    "model =  models.Sequential([\n",
    "    \n",
    "  layers.Conv2D(32 , (3,3),activation = 'relu',padding='valid', input_shape = INPUTSHAPE),  \n",
    "  layers.MaxPooling2D(2, padding='same'),\n",
    "  layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "  layers.MaxPooling2D(2, padding='same'),\n",
    "  layers.Dropout(0.3),\n",
    "  layers.Conv2D(128, (3,3), activation='relu',padding='valid'),\n",
    "  layers.MaxPooling2D(2, padding='same'),\n",
    "  layers.Dropout(0.3),\n",
    "  layers.GlobalAveragePooling2D(),\n",
    "  \n",
    "  layers.Dense(512 , activation = 'relu'),\n",
    "  layers.Dense(15, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Nadam', metrics = 'acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rxa1JYyXFJUA",
    "outputId": "6ccaa28d-307c-4d05-aada-e08ecc7e416a"
   },
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=8, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False)\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "            validation_data=(X_test,y_test),\n",
    "            epochs=25,\n",
    "            callbacks = [callback],batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihi2AQM5dTnq"
   },
   "source": [
    "Metrics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUjxCjI-VzcZ",
    "outputId": "71eed56e-19d9-4845-b675-881d4a7f9405",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(y_test,1), np.argmax(pred,1), target_names=classes))\n",
    "#number of records in the test set=support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7a9awBadYVm"
   },
   "source": [
    "### Ð¡onfusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8f49QfpzVhm"
   },
   "source": [
    "Using this matrix, you can understand in which classes\n",
    "\n",
    "\n",
    "model is wrong. (i.e. which class gets confused with the other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IldZacubVzZa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(np.argmax(y_test,1), np.argmax(pred,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sQu_Fm9HVMdu",
    "outputId": "48df4712-05f7-4696-9406-31799023b8ae"
   },
   "outputs": [],
   "source": [
    "import seaborn as snNew\n",
    "fig, ax = plt.subplots(figsize=(30,30))\n",
    "snNew.heatmap(cm, annot=True, xticklabels= classes, yticklabels= classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "y1 = []\n",
    "for data in tqdm(df.iterrows(),  desc='Progress'):\n",
    "        sig , sr = librosa.load(AUDIO_PATH + \"\\\\\" + data[1][0],sr = 44100)\n",
    "        sig_ = sig[0 : 110250]\n",
    "        mfcc_ = librosa.feature.mfcc(sig_ , sr=sr,hop_length = 640 , n_mfcc=40,dct_type=2)\n",
    "        x1.append(mfcc_)\n",
    "        y1.append(data[1][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(x1) \n",
    "y1 = np.array(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X Shape is: \", x1.shape)\n",
    "print(\"y Shape is: \", y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = tf.keras.utils.to_categorical(y1 , num_classes=50)\n",
    "x1 = x1.reshape(x1.shape[0], x1.shape[1], x1.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(np.argmax(y1,1), np.argmax(pred,1), target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r\"C:\\Users\\harsh\\Desktop\\concatenated audio(15 noises)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(file_names):\n",
    "    sig , sr = librosa.load(test_path + \"\\\\\" + i,sr = 44100)\n",
    "    sig_ = sig[0 : 441000]\n",
    "    mfcc_ = librosa.feature.mfcc(sig_ , sr=sr,hop_length = 2550 , n_mfcc=40,dct_type=2)\n",
    "    concat_test.append(mfcc_)\n",
    "    #y1.append(data[1][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test = np.array(concat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test = concat_test.reshape(concat_test.shape[0], concat_test.shape[1], concat_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test = np.array(concat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(concat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result=[]\n",
    "for i in classes[np.argmax(prediction,1)]:\n",
    "    prediction_result.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in classes[np.argmax(prediction,1)]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0,len(prediction_result)):\n",
    "    w = file_names[i].split(\".\")[0]\n",
    "    t = w.split(\"_and_\")\n",
    "    if prediction_result[i] in t:\n",
    "        print(1)\n",
    "        count = count+1\n",
    "    else:\n",
    "        print(0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Noise_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
